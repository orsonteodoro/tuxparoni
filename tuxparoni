#!/bin/bash

# Copyright 2019 Orson Teodoro <orsonteodoro@hotmail.com>
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to
# deal in the Software without restriction, including without limitation the
# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
# sell copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
# DEALINGS IN THE SOFTWARE.

#---

# NVD Data files are in public domain
# Obtained from https://nvd.nist.gov/vuln/data-feeds
# Patches are GPL-2, GPL-2+, or MIT depending on the original file.

#---

# Before using this tool

# Few arguments against using automated patching sample
# 1) It may mispatch; or create duplicate code blocks.
# 2) It may add a hunk that it shouldn't add.
# 3) All hunks need to be inspected manually for mispatches and unnecessary
#    duplicate hunks all for all 1000 patches (with possibly +3000 hunks) if
#    necessary.
# 4) Most likely broken if reliance on completely automated patching.
# 5) Sloppy tagging.  NVD mixes Patch with Exploit tags.  Patch implies fix;
#    nothing else.
# 6) Links contain references to a commit (or supposed patch) but doesn't say if
#    the commit is introducing the flaw.
# 7) Possibility of re-applying the flaw (due to sloppy tagging or
#    miscommunication of the report by the researcher) if no manual
#    inspection.  Should not use the word Patch because it is
#    dualistic / ambigious.  It's better to use Fix or Flaw instead of Patch.

# Arguments for using automated patching sample
# 1) Faster rate of processing 3000 with JSONs vs 100 by orders of magnitude
#    with manual entry of a new database in around the same timebox.
# 2) It saves time by orders of magnitude.

# Required dependencies
# jq
# bash
# wget or curl
# gunzip
# grep with perl regex support
# html2text
# pcregrep (found in the libpcre package)
# patchutils for filterdiff

# Optional dependencies
# kpatch
# linux kernel with livepatch or kpatch support
# gcc with toolchain to compile the kernel
# patchutils for combinediff

DIR=$(realpath $(dirname "$0"))

ARGS=($@)

NVD_JSON_SCHEMA_VERSION="1.1"
PRODUCT="linux"

G_CACHE_FOLDER="/var/cache/tuxparoni"
G_KERNEL_SOURCE_FOLDER="/usr/src/linux"
G_CUSTOM_PATCHES_DIR="${G_CACHE_FOLDER}/custom_patches"
G_LOGS="${G_CACHE_FOLDER}/logs"
G_KERNEL_TAG=""
G_KERNEL_SOURCE_BIN=""
G_MIN_YEAR_LIMIT="2002"
G_MAX_YEAR_LIMIT="2019"
G_MIN_YEAR="${G_MIN_YEAR_LIMIT}" # 2002 inclusive is the earliest, 2015 is year linux 4.0 was released
G_MAX_YEAR="${G_MAX_YEAR_LIMIT}"
G_DOWNLOAD_TOOL="curl" # can be wget or curl
G_KERNEL_TIMESTAMP=0
G_HTML2TEXT_WIDTH=320 # to avoid malformed patch
G_TUXPARONI_URL_RESOLVER_HASH="070cfae6eca08d1287929a5a7cf5b3ead7f2fe9ea740434422ebe48461041dd0" #sha256
G_UNATTENDED=0
G_REQ_CLEAR_CACHE=0
G_REQ_FETCH_JSONS=0
G_REQ_FETCH_PATCHES=0
G_REQ_DRY_TEST=0
G_REQ_REPORT=0
G_REQ_APPLY_PATCHES=0
G_REQ_KPATCH_MODULES=0
G_REQ_BUILD_KPATCHES=0
G_PATCH_DEFAULT_OPTIONS="-p1 -F 100"
G_FEEDS_DIR=""
G_JSONS_DIR=""
G_PATCHES_DIR=""
G_TEMP_DIR="/tmp"
CVE_ALLOW_RISKY_BACKPORTS=${CVE_ALLOW_RISKY_BACKPORTS:=0}
CVE_DELAY=${CVE_DELAY:=0}
CVE_FIX_REJECT_DISPUTED=${CVE_FIX_REJECT_DISPUTED:=0}
CVE_LANG=${CVE_LANG:=en}
CVE_FIX_TRUST_LEVEL_DEFAULT=$((0x00000001 | 0x00000002 | 0x00010000 | 0x00020000 | 0x00040000 \
| 0x00080000 | 0x04000000 | 0x01000000 | 0x01000000 \
| 0x01000000))
CVE_FIX_TRUST_LEVEL=${CVE_FIX_TRUST_LEVEL:=${CVE_FIX_TRUST_LEVEL_DEFAULT}}
G_PATCH_META_VERSION="1.0"
G_VERSION="1.3.2"

EOK=0

H_INFO="
$(basename $BASH_SOURCE) v${G_VERSION}
Copyright 2019 Orson Teodoro
License: MIT
"
H_HELP="
$(basename $BASH_SOURCE) <args>

tuxparoni is an automated CVE patcher frontend for the Linux kernel.

Args:
	-d, --delete			deletes caches to start from scratch
	-c, --cache-folder		points to place to store patches, processed jsons, json feeds
	-b, --kernel-bin		points to kernel binary location (e.g. /boot/vmlinuz)
	-s, --kernel-src		points to kernel sources location (e.g. /usr/src/linux)
	-g, --generate-kpatch-modules	generates kpatch modules
	-u,  --unattended		runs unattended
	-cj, --cmd-fetch-jsons		fetches, unpacks, filter NVD JSONs
	-cp, --cmd-fetch-patches	fetches, dedupes, tidys commits or patches
	-ct, --cmd-dry-test		does a dry run per CVE patch to determine if sources are vulunerable
	-cr, --cmd-report		shows a mini report per CVE
	-ca, --cmd-apply		applies patches
	-mx, --max-year			sets max year to process
	-mn, --min-year			sets min year to process
	-t, --temp			sets the temp dir
	--curl				downloads with curl (default)
	--wget				downloads with wget
	-h, --help			prints all the supported commands
	-v, --version			prints version info

Environmental variables:

	CVE_BLACKLIST_FIXES - space seperated string of CVEs to not apply fixes
			      in the form of CVE-2018-14498

	CVE_FIX_TRUST_LEVEL - a whitelist of class of commits or patches to apply
		0x00000001 - kernel.org repos
		0x00000002 - github torvalds
		0x00000004 - reserved
		0x00000008 - module maintainer(s)
		0x00010000 - immediate NVD links
		0x00020000 - indirect NVD links
		0x00040000 - corporate reviewed
		0x00080000 - major distro reviewed
		0x04000000 - major distro team suggested
		0x01000000 - tuxparoni patches
		0x01000000 - tuxparoni addendum class A
		0x01000000 - FOSS contributor
		0x10000000 - OSS contributor
		0x80000000 - patron
		0x80000000 - user patches
		0x00000000 - disallow untrusted
		0x00000000 - disallow incomplete
		0x00000001 | 0x00000002 | 0x00010000 | 0x00020000 | 0x00040000
			| 0x00080000 | 0x04000000 | 0x01000000 | 0x01000000
			| 0x01000000 - default

	CVE_FIX_REJECT_DISPUTED - rejects applying patches if disputed, 1 or 0,
				  default 0

	CVE_ALLOW_RISKY_BACKPORTS - allows to apply backports that might result
				    in damage or data loss, 1 or 0, default 0

	CVE_DELAY - puts a pause between reporting detailed CVEs, 1 or 0,
		    default 0

	CVE_LANG - en currently only supported for JSON feeds

Patches are licensed under GPL-2 or MIT.  See source of file.

CVE data is under the public domain and obtained and provided by the NVD which
was partly obtained from MITRE.
"

source "${DIR}/tuxparoni-url-resolver"
source "${DIR}/tuxparoni-conflict-resolver"

G_LAST_URL=""
download() {
	G_LAST_URL="${2}"
	if [[ "$2" =~ ^defunct \
	      || "$2" =~ ^banned \
	      || "$2" =~ ^flaw \
	      || "$2" =~ ^info ]] ; then
		return
	fi
	if [[ "${G_DOWNLOAD_TOOL}" == "curl" ]] ; then
		curl -s -L -C - -o $1 $2
		(( "$?" == 56 || "$?" == 55 )) \
			&& eerror "Network dead?  Stopping." && exit 1
	else
		wget -q -c -O $1 $2
		(( "$?" == 4 )) \
			&& eerror "Network dead?  Stopping." && exit 1
	fi
}

einfo() {
	echo -e "\e[92m*\e[0m $*"
}

einfow() {
	echo -e "\e[92m*\e[0m $*" | fold -s -w 80
}

ewarn() {
	echo -e "\e[33m*\e[0m $*"
}

ewarnw() {
	echo -e "\e[33m*\e[0m $*" | fold -s -w 80
}

eerror() {
	echo -e "\e[31m*\e[0m $*"
}

eerrorw() {
	echo -e "\e[31m*\e[0m $*" | fold -s -w 80
}

fetch_feeds() {
	einfo "Fetching feeds"
	local rdl_folder="https://nvd.nist.gov/feeds/json/cve/${NVD_JSON_SCHEMA_VERSION}/"
	for y in $(seq ${G_MIN_YEAR} ${G_MAX_YEAR}) recent modified ; do
		download "${G_FEEDS_DIR}/nvdcve-${NVD_JSON_SCHEMA_VERSION}-${y}.json.gz" \
			"${rdl_folder}/nvdcve-${NVD_JSON_SCHEMA_VERSION}-${y}.json.gz"
		download "${G_FEEDS_DIR}/nvdcve-${NVD_JSON_SCHEMA_VERSION}-${y}.meta" \
			"${rdl_folder}/nvdcve-${NVD_JSON_SCHEMA_VERSION}-${y}.meta"
		local expected_sz=$(grep "gzSize" \
			"${G_FEEDS_DIR}/nvdcve-${NVD_JSON_SCHEMA_VERSION}-${y}.meta" \
			| cut -f2 -d ":" | sed -e "s|[^0-9]||g")
		local x_sz=$(wc -c \
			"${G_FEEDS_DIR}/nvdcve-${NVD_JSON_SCHEMA_VERSION}-${y}.json.gz" \
			| cut -f1 -d " ")
		if [[ "${expected_sz}" != "${x_sz}" && "${expected_h}" != "${x_h}" ]] ; then
			echo -e \
"\e[41m\e[30m Failed \e[0m nvdcve-${NVD_JSON_SCHEMA_VERSION}-${y}.json.gz.  Clear cache."
			exit 1
		fi
		echo -e "\e[42m\e[30m Success \e[0m nvdcve-${NVD_JSON_SCHEMA_VERSION}-${y}.json.gz"
	done
}

unpack_feeds() {
	einfo "Unpacking feeds"
	pushd "${G_FEEDS_DIR}" > /dev/null
		for y in $(seq ${G_MIN_YEAR} ${G_MAX_YEAR}) recent modified ; do
			gunzip -q -f -k \
			nvdcve-${NVD_JSON_SCHEMA_VERSION}-${y}.json.gz
			local expected_sz=$(grep "size" \
				"${G_FEEDS_DIR}/nvdcve-${NVD_JSON_SCHEMA_VERSION}-${y}.meta" \
				| cut -f2 -d ":" | sed -e "s|[^0-9]||g")
			local x_sz=$(wc -c \
				"${G_FEEDS_DIR}/nvdcve-${NVD_JSON_SCHEMA_VERSION}-${y}.json" \
				| cut -f1 -d " ")
			local expected_h=$(grep "sha256" \
				"${G_FEEDS_DIR}/nvdcve-${NVD_JSON_SCHEMA_VERSION}-${y}.meta" \
				| cut -f2 -d ":" | sed -e "s|[^0-9A-Z]||g")
			expected_h=${expected_h,,}
			local x_h=$(sha256sum \
				"${G_FEEDS_DIR}/nvdcve-${NVD_JSON_SCHEMA_VERSION}-${y}.json" \
				| cut -f1 -d " ")
			if [[ "${expected_sz}" != "${x_sz}" && "${expected_h}" != "${x_h}" ]] ; then
				echo -e \
"\e[41m\e[30m Failed \e[0m nvdcve-${NVD_JSON_SCHEMA_VERSION}-${y}.json.  Clear cache."
				exit 1
			fi
			echo -e "\e[42m\e[30m Success \e[0m nvdcve-${NVD_JSON_SCHEMA_VERSION}-${y}.json"
		done
	popd > /dev/null
}

filter_jsons() {
	einfo "Filtering JSONs"
	for y in $(seq ${G_MIN_YEAR} ${G_MAX_YEAR}) recent modified ; do
		json_file="${G_JSONS_DIR}/nvdcve-${NVD_JSON_SCHEMA_VERSION}-${y}.json"
		jq "[.\"CVE_Items\"[] | {cveid:.cve.CVE_data_meta.ID, \
			desc: .cve.description.description_data[0].value, \
			severity3: .impact.baseMetricV3.cvssV3.baseSeverity, \
			severity2: .impact.baseMetricV2.severity, \
			refdata: .cve.references.reference_data[]} \
		    ] \
			| map(select( (contains({desc:\"linux\"}) \
				or contains({desc:\"Linux\"}) \
				or contains({desc:\"LiNUX\"}) \
				or contains({desc:\"LINUX\"}) \
			              ) \
			and (contains({desc:\"kernel\"}) \
				or contains({desc:\"Kernel\"}) \
				or contains({desc:\"KERNEL\"}) \
			    ) \
			and contains({refdata: {tags: [\"Patch\"]}}) \
				      ) \
			     )" \
			"${G_FEEDS_DIR}/nvdcve-${NVD_JSON_SCHEMA_VERSION}-${y}.json" \
			> "${json_file}"
		echo -e "\e[42m\e[30m Done \e[0m ${y}"
	done
}

# use CVSS v3 (four levels) but fall back to v2 (three levels)
get_severity() {
	local severity3=$(jq "[.[]] | .[${i}].severity3" "${json_file}" \
		| sed -r -e "s|\"||g")
	local severity2=$(jq "[.[]] | .[${i}].severity2" "${json_file}" \
		| sed -r -e "s|\"||g")
	if [[ "${severity3}" != "null" ]] ; then
		severity="${severity3}"
	elif [[ "${severity2}" != "null" ]] ; then
		severity="${severity2}"
	else
		severity="na"
	fi
	echo "${severity}"
}


# required preconditions: src, dest, cve_id, PRODUCT, module, url all must be filled prior
# optional preconditions: subject, tag1, tag2
_process_patch() {
	local is_processable=0

	if is_patch_good "${src}" ; then
		is_processable=1
	fi

	if is_html2text_permitted "${src}" ; then
		is_processable=1
	fi

	if [[ "${is_processable}" != "1" ]] ; then
		rm "${src}"
		return 1
	fi

	len=$(wc -c "${src}" | cut -f1 -d " ")
	if (( ${len} == 0 )) ; then
		rm "${src}"
		return 1
	else
		if is_html2text_permitted "${src}" ; then
			html2text -width ${G_HTML2TEXT_WIDTH} -utf8 -nobs "${src}" > "${src}.t"
			mv "${src}.t" "${src}"
		fi

		# reorder by timestamp for possibly combinediff
		local timestamp=0
		if is_patch_good "${src}" && grep -e "^Date:" "${src}" \
			> /dev/null ; then
			htimestamp=$(grep -r -e "^Date:" "${src}" | head -n 1 \
				| sed -e "s|[^a-zA-Z0-9:, +-]||g" \
				| sed -e "s|Date:[\t ]*||g" \
				| sed -r -e "s|\([A-Z]+\)||g" -e "s|[ A-Z]+$||")
			if echo "${url}" | cut -f4 -d " " | grep -q -e ":" ; then
				htimestamp=$(echo "${htimestamp}" \
					| sed -r -e \
"s|([A-Za-z]+)[,]? ([A-Za-z]+) ([0-9]+) ([0-9]{2}:[0-9]{2}:[0-9]{2}) ([0-9]{4})\
 ([+0-9-]+)|\1, \2 \3 \5 \4 \6|")
			fi
			timestamp=$(date -d "${htimestamp}" +%s)
		else
			cve_year=$(echo "${cve_id}" | cut -f2 -d "-")
			# put the unknown dates at the end of the queue; also
			# reduce code to consider leap year
			timestamp=$(($(date -d "1/1/$((${cve_year}+1))" +%s)-1))
		fi

		module=$(cat "${src}" \
			| grep -F -e "+++" | tail -n 1 \
			| cut -f2 -d " " \
			| sed -r -e "s|^[ab]/||g" \
			| sed -r -e "s#(.c|.h)\$##g" \
			| sed -e "s|[^a-zA-Z0-9_]|-|g")
		subject=$(get_sanitized_commit_subject \
			"${src}")
		# 255 filename limit so strink as much as possible
		#local dest_fn="${cve_id}--${PRODUCT}--${module}--${subject}.patch" # preferred
		local severity=$(get_severity)

		# the naming scheme was selected for admins/endusers to pick
		# based on hardware of the device.

		# module: hints subsystem and driver.
		# severity: CVSS v3 but falls back to v2.
		# timestamp: unix timestamp of the commit.  Useful for
		#            reordering patches.
		# tags: additional metadata to filter for the device/arch.
		tags=""
		if [[ -n "${tag1}" ]] ; then
			tags+="-${tag1}"
		fi
		if [[ -n "${tag2}" ]] ; then
			tags+="-${tag2}"
		fi
		tags="${tags,,}"
		tags=$(echo "${tags}" | sed -e "s|\.|_|g")
		local dest_fn_base=\
"${timestamp}-${cve_id}-${severity,,}-${module,,}${tags}"
		local dest_fn="${dest_fn_base}.patch"
		local dest="${G_PATCHES_DIR}/${dest_fn}"
		mv "${src}" "${dest}"

		if cat "${dest}" \
			| grep -F 'Diff 1 not found or parse error; hopeless!'
		then
			rm "${dest}"
			return 1
		fi

		if ! is_patch_good "${dest}" ; then
			rm "${dest}"
			return 1
		fi
		echo -e "\e[42m\e[30m Accepted \e[0m ${cve_id} ${dest_fn} ${G_LAST_URL}"

		# for drytest, report, and filtering drivers/subsystems for
		# custom hardware setups
		local meta_path="${G_PATCHES_DIR}/${dest_fn_base}.meta"
		echo "meta_version: ${G_PATCH_META_VERSION}" > "${meta_path}"
		echo "severity: ${severity}" >> "${meta_path}"
		echo "timestamp: ${timestamp}" >> "${meta_path}"
		echo "subject: ${subject}" >> "${meta_path}"
		echo "original_url: ${url}" >> "${meta_path}"
		echo "last_url: ${G_LAST_URL}" >> "${meta_path}"
		[[ -n "${tag1}" ]] \
			&& echo "tag1: ${tag1}" >> "${meta_path}"
		[[ -n "${tag2}" ]] \
			&& echo "tag2: ${tag2}" >> "${meta_path}"
		# can be used to filter for device drivers
		local files=$(cat "${dest}" | grep -P -e "^[+-]{3} " \
			| cut -c 5- | sed -e "s|^[a,b]/||g" | uniq \
			| cut -f1 -d $' ' | cut -f1 -d $'\t' | tr "\n" " ")
		echo "files: ${files}" >> "${meta_path}"
	fi
	return 0
}

fetch_patches() {
	for y in $(seq ${G_MIN_YEAR} ${G_MAX_YEAR}) recent modified ; do
		local json_file="${G_JSONS_DIR}/nvdcve-${NVD_JSON_SCHEMA_VERSION}-${y}.json"
		local cve_length=$(jq '[.[]] | length' "${json_file}")

		for i in $(seq 0 $((${cve_length}-1))) ; do
			local cve_id
			local cve_id=$(jq "[.[]] | .[${i}].cveid" \
				"${json_file}" | sed -r -e "s|\"||g")

			local url=$(jq ".[${i}].refdata.url" "${json_file}" \
				| sed -r -e "s|\"||g")
			local url_raw=$(get_patch_direct_link "${url}" "${cve_id}")
			local src="${G_PATCHES_DIR}/${cve_id}.patch"
			if ! download_patch "${url_raw}" "${cve_id}" "${src}" ; then
				if [[ "${G_LAST_URL}" =~ ^info ]] ; then
					url=$(echo "${G_LAST_URL}" | sed -r -e "s|^info:  ||")
					echo -e "\e[46m\e[30m   Info   \e[0m ${cve_id} ${url}"
				else
					G_LAST_URL=$(echo "${G_LAST_URL}" \
						| sed -r -e "s#^(flaw|defunct|banned):  ##")
					echo -e "\e[41m\e[30m Rejected \e[0m ${cve_id} ${url} -> ${G_LAST_URL}"
				fi
			fi
		done
	done
}

get_sanitized_commit_subject() {
	local fn="${1}"
	echo $(cat "${fn}" | grep -F "Subject" | head -n 1 \
		| sed -r -e "s|Subject: ||g" | sed -r -e "s|:|_|" -e "s| |_|g" \
		-e "s|\(\)|fn|g" -e "s|[^A-Za-z0-9._-]||g" -e "s|\.|_|g")
}

# wipe, download
_wd() {
	local url="${1}"
	local src="${2}"
	cat /dev/null > "${src}"
	download "${src}" "${url}"
}

_reset_tags() {
	unset tag1
	unset tag2
}

ban_commit() {
	local url="${1}"

	# openwall says introduced flaw, but nvd marks it as patch
	if [[ "${url}" =~ "129a72a0d3c8e139a04512325384fe5ac119e74" ]] ; then
		url="flaw:  ${url}"
	elif [[ "${url}" =~ secunia\.com ]] ; then
		url="defunct:  ${url}"
	elif [[ "${url}" =~ "codeaurora.org/security-bulletin/" \
		|| "${url}" =~ "android.com/security/bulletin/" \
		|| "${url}" =~ "redhat.com/support/errata/RHSA-" \
		|| "${url}" =~ "redhat.com/errata/RHSA-" \
		|| "${url}" =~ "novell.com/linux/security/advisories/" \
		|| "${url}" =~ "debian.org/security/"[0-9]{4}"/dsa" \
		|| "${url}" =~ "kernel.org".*"ChangeLog-"[0-9.]+$ \
		|| "${url}" =~ "show_bug.cgi" \
		|| "${url}" =~ "bugs.launchpad.net" ]] ; then
		# scraping from any bugzilla or dynamic page directly
		# is dangerous.  An attacker has carte blanche freedom
		# to post flaw if topic is not locked and rogue
		# comment is not removed immediately.
		url="info:  ${url}"
	fi
	echo "${url}"
}

# provides links directly to raw patch
get_patch_direct_link() {
	local url="${1}"
	local cve_id="${2}"

	if [[ "${url}" =~ ^"http://" ]] ; then
		url=$(echo "${url}" | sed -r -e "s|^http://|https://|g")
	fi

	url=$(ban_commit "${url}")

	if [[ "${url}" =~ "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git" ]] ; then
		local h=$(echo "${url}" | grep -o -P -e "([a-z0-9]+)\$")
		url="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/patch/?id=${h}"
	elif [[ "${url}" =~ "git.kernel.org/linus/" ]] ; then
		local h=$(echo "${url}" | grep -o -P -e "([a-z0-9]+)\$")
		url="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/patch/?id=${h}"
	elif [[ "${url}" =~ www\.kernel\.org \
		&& "${url}" =~ "hb=" ]]
	then
		local h=$(echo "${url}" | sed -r -e "s|.*hb=([0-9a-z]{40}).*|\1|g")
		local p=$(echo "${url}" | cut -f2 -d "?" \
			| cut -f1 -d ";" | sed -r -e "s|p=||" \
			| sed -e "s|linux-[0-9.]*.git|linux.git|g")
		url="https://git.kernel.org/pub/scm/${p}/patch/?id=${h}"
	elif [[ ( "${url}" =~ git\.kernel\.org || \
		  "${url}" =~ www\.kernel\.org ) \
		&& ( "${url}" =~ ";a=commitdiff;" \
		  || "${url}" =~ ";a=commit;") \
		&& ! ( "${url}" =~ "hb=" ) ]]
	then
		local p=$(echo "${url}" | cut -f2 -d "?" \
			| cut -f1 -d ";" | sed -r -e "s|p=||" \
			| sed -e "s|linux-[0-9.y]*.git|linux.git|g")
		local h=$(echo "${url}" | grep -o -P -e ";h=([a-z0-9]+)" \
			| sed -r -e "s|;h=||")
		url="https://git.kernel.org/pub/scm/${p}/patch/?id=${h}"
	elif [[ "${url}" =~ "/commit/".*(\&|\?)"id="[0-9a-z]+ ]] ; then
		url=$(echo "${url}" | sed -e "s|/commit/|/patch/|")
	elif [[ "${url}" =~ lore\.kernel\.org ]] ; then
		url=$(echo "${url}" | sed -r -e "s|/T/(#u)?|/|g")
		if [[ "${url}" =~ /$ ]] ; then
			url="${url}raw"
		else
			url="${url}/raw"
		fi
	elif [[ "${url}" =~ patchwork\.kernel\.org ]] ; then
		if [[ "${G_DOWNLOAD_TOOL}" == "curl" ]] ; then
			url=$(curl -L -s -o /dev/null -w %{url_effective} \
				"${url}")
			url="${url}mbox"
		else
			url=$(wget -O /dev/null "${url}" 2>&1 \
				| grep "http.*\[following\]" \
				| sed -e "s|Location: ||" \
				-e "s|\[following\]||g")
			url="${url}mbox"
		fi
	elif [[ "${url}" =~ patchwork ]] ; then
		url="${url}mbox"
	elif [[ "${url}" =~ lkml\.org ]] ; then
		url=$(echo "${url}" | sed -e "s|/lkml/|/lkml/diff/|g" \
			| echo "$(cat -)/1")
	elif [[ "${url}" =~ github\.com && ! ( "${url}" =~ \.patch$ ) \
		&& ! ( "${url}" =~ \.md$ ) \
		&& ! ( "${url}" =~ "/issues/" ) ]] ; then
		url="${url}.patch"
	elif [[ "${url}" =~ salsa\.debian\.org \
		&& "${url}" =~ "/commit/" ]]
	then
		url="${url}.patch"
	elif [[ "${url}" =~ marc.info ]] ; then
		url="${url}&q=mbox"
	elif [[ "${url}" =~ "securityfocus.com/bid" ]] ; then
		url="${url}/solution"
	fi
	url=$(fix_direct_download "${url}" "${cve_id}")
	echo "${url}"
}

is_patch_good() {
	local f="${1}"
	if pcregrep -s -M "^--- .*\n^\+\+\+ .*\n" "${f}" 2>/dev/null 1>/dev/null ; then
		return 0
	else
		return 1
	fi
}

is_html2text_permitted() {
	local f="${1}"
	local is_html=0
	cat "${f}" | grep -q -F -e '</html>' && is_html=1
	if [[ "${is_html}" == "1" ]] && is_patch_good "${f}" ; then
		return 0
	else
		return 1
	fi
}

# skips non patchfiles
download_patch() {
	local url="${1}"
	local cve_id="${2}"
	local src="${3}"

	if [[ "${url}" =~ \.zip$|\.xz$|\.gz$|\.bz2$ ]] ; then
		# don't download patchsets or kernel incremental patches
		return 1
	elif [[ "${url}" =~ "source.android.com/security/bulletin" ]] ; then
		return 1
	fi
#		|| "${url}" =~ "www.codeaurora.org"

	_reset_tags

	# multipatch
	if process_multipatch "${url}" "${cve_id}" "${src}" ; then
		return 0
	fi

	cat /dev/null > "${src}"
	download "${src}" "${url}"
	if _process_patch ; then
		return 0
	fi

	return 1
}

# this only reports based on configuration data
report_cves_json_only() {
	# todo
	:;
}

# this only reports if the patch was applied and doesn't consider CVEs without patches at the moment
report_cves_patches_only() {
	pushd "${G_KERNEL_SOURCE_FOLDER}" > /dev/null
	# 2002
	for y in $(seq ${G_MIN_YEAR} ${G_MAX_YEAR}) recent modified ; do
		local json_file="${G_JSONS_DIR}/nvdcve-${NVD_JSON_SCHEMA_VERSION}-${y}.json"
		einfo "Processing ${json_file}"
		local cve_length=$(jq '[.[]] | length' "${json_file}")

		local previous_cve=""
		for i in $(seq 0 $((${cve_length}-1))) ; do
			local cve_id=$(jq "[.[]] | .[${i}].cveid" "${json_file}" \
				| sed -r -e "s|\"||g")
			[[ "${previous_cve}" == "${cve_id}" ]] && continue
			previous_cve=${cve_id}

			local severity=$(get_severity)
			local desc=$(jq "[.[]] | .[${i}].desc" "${json_file}" \
				| sed -r -e "s|\"||g")

			local is_vulnerable="0"
			local P=$(ls "${G_PATCHES_DIR}"/*${cve_id}*.patch 2>/dev/null)
			for p in ${P} ; do
				patch --dry-run ${G_PATCH_DEFAULT_OPTIONS} \
					-i "${p}" 2> /dev/null 1> /dev/null
				is_applied="$?"
				is_vulnerable=$((${is_vulnerable} | ${is_applied}))
			done

			local len_P=$(echo "${P[@]}" | wc -c)
			if [[ "${is_vulnerable}" == "0" ]] && (( ${len_P} > 1 )) ; then
				einfo "${cve_id}"
				einfow "Description:  ${desc}"
				einfo "NIST NVD:  https://nvd.nist.gov/vuln/detail/${cve_id}"
				einfo "MITRE:  https://cve.mitre.org/cgi-bin/cvename.cgi?name=${cve_id}"
				#local url=$(jq ".[${i}].refdata.url" "${json_file}" | sed -r -e "s|\"||g")
				#einfo "Patch (message):  ${url}"
				#local url_raw=$(get_patch_direct_link "${url}" "${cve_id}" \
				#	| sed -r -e "s#^(flaw|defunct|banned|info):  ##")
				#einfo "Patch (raw):  ${url_raw}"
				if [[ "${severity}" == "CRITICAL" ]] ; then
					einfo "Severity:  \e[100mCRITICAL\e[0m"
				elif [[ "${severity}" == "HIGH" ]] ; then
					einfo "Severity:  \e[41mHIGH\e[0m"
				elif [[ "${severity}" == "MEDIUM" ]] ; then
					einfo "Severity:  \e[43m\e[30mMedium\e[0m"
				elif [[ "${severity}" == "LOW" ]] ; then
					einfo "Severity:  \e[44m\e[30mLow\e[0m"
				else
					einfo "Severity:  N/A"
				fi
				einfo "Vulnerable: possibly yes"
				einfo ""
			fi
		done
	done
	popd > /dev/null
}

drytest_cves() {
	einfo "Drytesting"
	P=$(ls "${G_PATCHES_DIR}"/*.patch)
	local c=0
	local total=0
	local bad_patches=0
	local bad_ports=0
	pushd "${G_KERNEL_SOURCE_FOLDER}" > /dev/null
	local t_out=$(tempfile)
	local displayed_kernel_release=0
	for p in ${P} ; do
		total=$((total+1))
		local cve_id=$(basename "${p}" | cut -f2-4 -d "-")
		local patch_timestamp=$(basename "${p}" | cut -f1 -d "-")
		if (( ${patch_timestamp} >= ${G_KERNEL_TIMESTAMP} \
			&& ${displayed_kernel_release} == 0 ))
		then
			echo -e "\e[44m\e[30m Kernel Released \e[0m"
			displayed_kernel_release=1
		fi
		cat /dev/null > "${t_out}"
		local is_failed_at=0
		local is_file_missing=0
		local is_malformed=0
		local is_previously_applied=0
		local is_fuzzy_succeeded=0
		local is_garbage=0
		echo -e $(patch --dry-run ${G_PATCH_DEFAULT_OPTIONS} \
			-i "${p}" 2>&1) \
			| grep -q -F -e "succeeded at" && is_fuzzy_succeeded=1
		echo -e $(patch --dry-run ${G_PATCH_DEFAULT_OPTIONS} \
			-i "${p}" 2>&1) \
			| grep -q -F -e "FAILED at" && is_failed_at=1
		echo -e $(patch --dry-run ${G_PATCH_DEFAULT_OPTIONS} \
			-i "${p}" 2>&1) \
			| grep -q -F -e "can't find file" && is_file_missing=1
		echo -e $(patch --dry-run ${G_PATCH_DEFAULT_OPTIONS} \
			-i "${p}" 2>&1) \
			| grep -q -F -e "malformed" && is_malformed=1
		echo -e $(patch --dry-run ${G_PATCH_DEFAULT_OPTIONS} \
			-i "${p}" 2>&1) \
			| grep -q -F -e "Reversed (or previously applied)" \
			&& is_previously_applied=1
		echo -e $(patch --dry-run ${G_PATCH_DEFAULT_OPTIONS} \
			-i "${p}" 2>&1) \
			| grep -q -F -e "Only garbage was found in the patch input." \
			&& is_garbage=1
		patch --dry-run ${G_PATCH_DEFAULT_OPTIONS} \
			-i "${p}" 2> /dev/null 1> /dev/null
		local is_vulnerable="$?"
		if [[ "${is_previously_applied}" == "1" \
			&& "${is_fuzzy_succeeded}" != "1" \
			&& "${is_failed_at}" != "1" \
			&& "${is_file_missing}" != "1" \
			&& "${is_malformed}" != "1" ]]
		then
			echo -e "\e[42m\e[30m   Passed   \e[0m ${cve_id}"
			echo -e "\e[42m\e[30m   Passed   \e[0m ${cve_id}" \
			>> "${G_LOGS}/drytest"
		elif [[ "${is_failed_at}" == "1" || "${is_file_missing}" == "1" ]] ; then
			local h=$(sha256sum "${p}" | cut -f1 -d " ")
			bad_ports=$((${bad_ports}+1))
			echo -e \
"\e[100m\e[97m  Bad port  \e[0m ${cve_id}"
			echo -e \
"\e[100m\e[97m  Bad port  \e[0m ${cve_id} sha256=${h} path=${p}" \
			>> "${G_LOGS}/drytest"
		elif [[ "${is_malformed}" == "1" || "${is_garbage}" == "1" ]] ; then
			local h=$(sha256sum "${p}" | cut -f1 -d " ")
			bad_patches=$((${bad_patches}+1))
			echo -e \
"\e[100m\e[97m  Bad patch \e[0m ${cve_id}"
			echo -e \
"\e[100m\e[97m  Bad patch \e[0m ${cve_id} sha256=${h} path=${p}" \
			>> "${G_LOGS}/drytest"
		elif [[ "${is_vulnerable}" == "0" ]] ; then
			echo -e "\e[41m Vulnerable \e[0m ${cve_id}"
			c=$((c+1))
		elif [[ "${is_previously_applied}" == 1 ]] ; then
			local h=$(sha256sum "${p}" | cut -f1 -d " ")
			# Try to avoid duplicate hunk problem
			echo -e \
"\e[100m\e[97m  Rejected  \e[0m ${cve_id}"
			echo -e \
"\e[100m\e[97m  Rejected  \e[0m ${cve_id} sha256=${h} path=${p} (dupe hunk problem avoidance)" \
			>> "${G_LOGS}/drytest"
		else
			eerror \
"uncaught case is_failed_at=${is_failed_at} is_file_missing=${is_file_missing} \
is_malformed=${is_malformed} is_previously_applied=${is_previously_applied} \
is_fuzzy_succeeded=${is_fuzzy_succeeded} is_vulnerable=${is_vulnerable}"
			eerror "Patch: ${p}"
			exit 1
		fi
	done
	popd > /dev/null
	rm "${t_out}"
	local hunks=$(grep -r -e "^@@" "${G_PATCHES_DIR}" | wc -l)
	einfo \
"${c} vulnerabilities detected, ${total} total patches tested, ${bad_patches} \
bad patches, ${bad_ports} bad backports or forwardports patches, ${hunks} \
hunks involved"
}

is_patch_authorized() {
	local cve_id="${1}"
	local original_url="${2}"
	local direct_download_url="${3}"
	for c in ${CVE_BLACKLIST_FIXES} ; do
		if [[ "${c}" == "${cve_id}" ]] ; then
			return 1
		fi
	done
	return 0
}

# true / triage patch
# idea is to apply then do micro changes on the broken hunk
tpatch() {
	local patch_path="${patch_path}"
	patch ${G_PATCH_DEFAULT_OPTIONS} -i "${patch_path}" || true
	echo -e "\e[100m\e[97m  Triaged  \e[0m ${cve_id} ${patch_patch}"
}

# exit if broken
epatch() {
	local patch_path="${patch_path}"
	patch ${G_PATCH_DEFAULT_OPTIONS} -i "${patch_path}"
	if [[ "$?" != "0" ]] ; then
		echo -e "\e[100m\e[97m   Failed  \e[0m ${cve_id} ${patch_patch}"
		exit 1
	else
		echo -e "\e[100m\e[97m   Applied  \e[0m ${cve_id}"
	fi
}

# Template function, it should be defined in tuxparoni-conflict-resolver as
# conflict_resolver with custom entries like below per each sha256sum.
# The failed dry run will spit out a sha256 of the failed backport which can be used
# to backport.

# This will apply to custom or fowardport patches not just backport patches.
# You may use this to apply more that one patch per failed patch.
# You may use this to apply a sequence of patches or unreported patches.
# You will use the patch_hash as like a hook.
# You may use this to skip patches.

# We don't distribute custom backport patches at the moment because of licensing,
# but it left to custom kernel maintainers.

# Consumers are responsible to runnning patch, helpers tpatch and dpatch are
# provided.

# return 0 if you applied the patch
# return 1 if it doesn't need an alterantive patch and it will proceed with
# patching.
conflict_resolver_default() {
	local cve_id="${1}"
	local patch_path="${2}" # original patch which can be used to revert or
				# partially apply it
	local patch_hash=$(sha256sum "${patch_path}" | cut -f1 -d " ")
	local alterative_patch=""
	if [[ "${patch_hash}" == "blah" ]] ; then
		# path to patch
		alternative_patch="${G_CUSTOM_PATCHES_DIR}/blah.patch"

		epatch "${alternative_patch}"
		return 0
	fi

	return 1
}

apply_patches() {
	einfo "Applying"
	P=$(ls "${G_PATCHES_DIR}"/*.patch)
	local c=0
	local total=0
	local bad_patches=0
	local bad_ports=0
	pushd "${G_KERNEL_SOURCE_FOLDER}" > /dev/null
	local t_out=$(tempfile)
	local displayed_kernel_release=0
	for p in ${P} ; do
		total=$((total+1))
		local cve_id=$(basename "${p}" | cut -f2-4 -d "-")
		local patch_timestamp=$(basename "${p}" | cut -f1 -d "-")
		if (( ${patch_timestamp} >= ${G_KERNEL_TIMESTAMP} \
			&& ${displayed_kernel_release} == 0 )) ; then
			echo -e "\e[44m\e[30m Kernel Released \e[0m"
			displayed_kernel_release=1
		fi
		cat /dev/null > "${t_out}"
		# -f
		local is_failed_at=0
		local is_file_missing=0
		local is_malformed=0
		local is_previously_applied=0
		local is_fuzzy_succeeded=0
		local is_garbage=0
		echo -e $(patch --dry-run ${G_PATCH_DEFAULT_OPTIONS} \
			-i "${p}" 2>&1) \
			| grep -q -F -e "succeeded at" && is_fuzzy_succeeded=1
		echo -e $(patch --dry-run ${G_PATCH_DEFAULT_OPTIONS} \
			-i "${p}" 2>&1) \
			| grep -q -F -e "FAILED at" && is_failed_at=1
		echo -e $(patch --dry-run ${G_PATCH_DEFAULT_OPTIONS} \
			-i "${p}" 2>&1) \
			| grep -q -F -e "can't find file" && is_file_missing=1
		echo -e $(patch --dry-run ${G_PATCH_DEFAULT_OPTIONS} \
			-i "${p}" 2>&1) \
			| grep -q -F -e "malformed" && is_malformed=1
		echo -e $(patch --dry-run ${G_PATCH_DEFAULT_OPTIONS} \
			-i "${p}" 2>&1) \
			| grep -q -F -e "Reversed (or previously applied)" \
			&& is_previously_applied=1
		echo -e $(patch --dry-run ${G_PATCH_DEFAULT_OPTIONS} \
			-i "${p}" 2>&1) \
			| grep -q -F -e "Only garbage was found in the patch input." \
			&& is_garbage=1
		patch --dry-run ${G_PATCH_DEFAULT_OPTIONS} \
			-i "${p}" 2> /dev/null 1> /dev/null
		local is_vulnerable="$?"
		if [[ "${is_previously_applied}" == "1" \
			&& "${is_fuzzy_succeeded}" != "1" \
			&& "${is_failed_at}" != "1" \
			&& "${is_file_missing}" != "1" \
			&& "${is_malformed}" != "1" ]]
		then
			echo -e "\e[42m\e[30m   Passed   \e[0m ${cve_id}"
		elif [[ "${is_failed_at}" == "1" || "${is_file_missing}" == "1" ]] ; then
			bad_ports=$((${bad_ports}+1))
			echo -e "\e[100m\e[97m  Bad port  \e[0m ${cve_id} file=${p}"
		elif [[ "${is_malformed}" == "1" || "${is_garbage}" == "1" ]] ; then
			bad_patches=$((${bad_patches}+1))
			echo -e "\e[100m\e[97m  Bad patch \e[0m ${cve_id} file=${p}"
		elif [[ "${is_vulnerable}" == "0" ]] ; then
			if is_patch_authorized "${cve_id}" "${}" "${}" ; then
				echo -e "\e[41m Applied \e[0m ${cve_id}"
				if declare -f conflict_resolver > /dev/null ; then
					if conflict_resolver "${cve_id}" \
						"${p}" ; then
						:;
					else
						patch ${G_PATCH_DEFAULT_OPTIONS} \
							-i "${p}"
					fi
				else
					patch ${G_PATCH_DEFAULT_OPTIONS} \
						-i "${p}"
				fi
			else
				echo -e "\e[100m\e[97m  Rejected  \e[0m ${cve_id} (unauthorized)"
			fi
			c=$((c+1))
		elif [[ "${is_previously_applied}" == 1 ]] ; then
			# Try to avoid duplicate hunk problem
			echo -e "\e[100m\e[97m  Rejected  \e[0m ${cve_id} file=${p} (hp)"
		else
			eerror "uncaught case"
			exit 1
		fi
	done
	popd > /dev/null
	rm "${t_out}"
	local hunks=$(grep -r -e "^@@" "${G_PATCHES_DIR}" | wc -l)
	einfo \
"${c} vulnerabilities detected, ${total} total patches tested, ${bad_patches} \
bad patches, ${bad_ports} bad backports or forwardports patches, ${hunks} \
hunks involved"
}

generate_kpatch_modules() {
	P=$(ls "${G_PATCHES_DIR}"/*.patch)
	pushd "${G_KERNEL_SOURCE_FOLDER}" > /dev/null
	for p in ${P} ; do
		local cve_id=$(echo "${p}" | sed -r -e "s|(CVE-[0-9]+-[0-9]+).*|\1|")
		local p_abs_path="${p}"
		einfo "Testing patch at ${p_path}"
		patch -f --dry-run ${G_PATCH_DEFAULT_OPTIONS} -i "${p_abs_path}" 2>&1 > /dev/null
		if [[ "$?" == "0" ]] ; then
			ewarn "Kernel may be vulnerable to ${cve_id}.  Generating live patch."
			kpatch-build -t "${G_KERNEL_SOURCE_BIN}" "${p_abs_path}"
		else
			einfo "Kernel may not be vulnerable to ${cve_id}."
		fi
		echo -e "\n"
	done
	popd > /dev/null
}

get_tag() {
	if [[ -d "${G_KERNEL_SOURCE_FOLDER}" ]] ; then
		local version=$(grep -F -e "VERSION" \
			"${G_KERNEL_SOURCE_FOLDER}/Makefile" | head -n1 \
			| cut -f2 -d "=" | sed -e "s| ||g")
		local patchlevel=$(grep -F -e "PATCHLEVEL" \
			"${G_KERNEL_SOURCE_FOLDER}/Makefile" | head -n1 \
			| cut -f2 -d "=" | sed -e "s| ||g")
		local sublevel=$(grep -F -e "SUBLEVEL" \
			"${G_KERNEL_SOURCE_FOLDER}/Makefile" | head -n1 \
			| cut -f2 -d "=" | sed -e "s| ||g")
		local extraversion=$(grep -F -e "EXTRAVERSION" \
			"${G_KERNEL_SOURCE_FOLDER}/Makefile" | head -n1 | \
			cut -f2 -d "=" | sed -e "s| ||g")
		echo "${version}.${patchlevel}.${sublevel}${extraversion}"
	fi
}

setup_globals() {
	G_FEEDS_DIR="${G_CACHE_FOLDER}/feeds"
	G_JSONS_DIR="${G_CACHE_FOLDER}/jsons"
	G_PATCHES_DIR="${G_CACHE_FOLDER}/patches"
	G_CUSTOM_PATCHES_DIR="${G_CACHE_FOLDER}/custom_patches"
	G_LOGS="${G_CACHE_FOLDER}/logs"
}

_merged_mkdir() {
	local path="${1}"
	mkdir -p "${path}"
	chmod 0750 "${path}"
	chown root:root "${path}"
}

setup_cache() {
	_merged_mkdir "${G_CACHE_FOLDER}"
	_merged_mkdir "${G_FEEDS_DIR}"
	_merged_mkdir "${G_JSONS_DIR}"
	_merged_mkdir "${G_PATCHES_DIR}"
	_merged_mkdir "${G_LOGS}"
}

clear_cache() {
	einfo "Wiping cache"
	einfo "G_FEEDS_DIR=${G_FEEDS_DIR}"
	rm -rf "${G_FEEDS_DIR}"
	rm -rf "${G_JSONS_DIR}"
	rm -rf "${G_PATCHES_DIR}"
	rm -rf "${G_LOGS}"
}

arg_parse() {
	#echo "ARGS=${ARGS[@]}"
	while (( ${#ARGS[@]} > 0 )) ; do
		arg="${ARGS[0]}"
		ARGS=("${ARGS[@]:1}")
		case "$arg" in
			-s|--kernel-src)
				G_KERNEL_SOURCE_FOLDER="${ARGS[0]}"
				ARGS=("${ARGS[@]:1}")
				;;
			-b|--kernel-bin)
				G_KERNEL_SOURCE_BIN="${ARGS[0]}"
				ARGS=("${ARGS[@]:1}")
				;;
			-t|--kernel-tag)
				G_KERNEL_TAG="${ARGS[0]}"
				ARGS=("${ARGS[@]:1}")
				;;
			-c|--cache-folder)
				G_CACHE_FOLDER="${ARGS[0]}"
				ARGS=("${ARGS[@]:1}")
				;;
			-d|--delete)
				G_REQ_CLEAR_CACHE="1"
				;;
			-g|--generate-kpatch-modules)
				G_REQ_BUILD_KPATCHES="1"
				;;
			-u|--unattended)
				G_UNATTENDED="1"
				;;
			-cj|--cmd-fetch-jsons)
				G_REQ_FETCH_JSONS="1"
				;;
			-cp|--cmd-fetch-patches)
				G_REQ_FETCH_PATCHES="1"
				;;
			-ct|--cmd-dry-test)
				G_REQ_DRY_TEST="1"
				;;
			-cr|--cmd-report)
				G_REQ_REPORT="1"
				;;
			-ca|--cmd-apply)
				G_REQ_APPLY_PATCHES="1"
				;;
			-mx|--max-year)
				G_MAX_YEAR="${ARGS[0]}"
				ARGS=("${ARGS[@]:1}")
				;;
			-mn|--min-year)
				G_MIN_YEAR="${ARGS[0]}"
				ARGS=("${ARGS[@]:1}")
				;;
			-t|--temp)
				G_TEMP_DIR="${ARGS[0]}"
				ARGS=("${ARGS[@]:1}")
				;;
			--curl)
				G_DOWNLOAD_TOOL="curl"
				;;
			--wget)
				G_DOWNLOAD_TOOL="wget"
				;;
			--version|-version|-ver)
				echo "${H_INFO}"
				exit ${EOK}
				;;
			--help|-help|-h)
				echo "${H_HELP}"
				exit ${EOK}
				;;
			*)
		esac
	done
}

kpatch_combine() {
	#todo
	:;
}

get_kernel_timestamp() {
	local ver="${1}"

	local sublevel=$(echo "${ver}" | cut -f3 -d '.')
	if [[ "${sublevel}" == "0" ]] ; then
		ver=$(echo "${ver}" | cut -f1-2 -d '.')
	fi

	local t=$(tempfile)
	# strange bug
	if ! wget -q -O "${t}" \
"https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git/commit/?h=v${ver}"
	then
		eerror "Failed network, retry."
		exit 1
	fi
	html2text -width ${G_HTML2TEXT_WIDTH} -utf8 -nobs "${t}" > "${t}.t"
	mv "${t}.t" "${t}"
	local ret=$(cat "${t}" | grep -P -e "^committer" | grep -o -P -e \
"[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2} (\-|\+|[ ])*[0-9]{4}")
	date -d "${ret}" +%s
	rm "${t}"
}

dedupe_patches_by_hash() {
	einfo "Running deduper"
	local t1=$(tempfile)
	sha1sum "${G_PATCHES_DIR}"/* | sort | cut -c 1-40 > "${t1}"
	local t2=$(tempfile)
	sha1sum "${G_PATCHES_DIR}"/* | sort | cut -c 1-40 | uniq > "${t2}"
	D=$(diff -urp "${t1}" "${t2}" | grep -e "^-" | cut -c 2- | tail -n +2 | uniq)

	for d in ${D} ; do
		F=($(sha1sum "${G_PATCHES_DIR}"/* | grep "${d}" | cut -f3 -d " "))
		F=(${F[@]:1})
		while (( ${#F[@]} > 0 )) ; do
			f="${F[0]}"
			rm "${f}" && \
			einfo "\e[100m\e[30m Removed \e[0m ${f}"
			F=("${F[@]:1}")
		done
	done
	rm "${t1}" "${t2}"
}

# this will usually process any patch that didn't get obtained from a
# git repo.
tidy_patches() {
	einfo "Running patch tidy"
	for f in $(ls "${G_PATCHES_DIR}"/*.patch) ; do
		local t=$(tempfile)
		if ! ( cat "${f}" | head -n 1 | tail -n +1 \
			| grep -q -P -e "^From [0-9a-z]{40} " )
		then
			einfo "Tidying ${f}"
			filterdiff "${f}" > "${t}"
			mv "${t}" "${f}"
		fi
		[ -e "${t}" ] && rm "${t}"
	done
}

review_envars() {
	einfo "CVE_BLACKLIST_FIXES=${CVE_BLACKLIST_FIXES}"
	einfo "CVE_FIX_TRUST_LEVEL=${CVE_FIX_TRUST_LEVEL}"
	einfo "CVE_FIX_REJECT_DISPUTED=${CVE_FIX_REJECT_DISPUTED}"
	einfo "CVE_ALLOW_RISKY_BACKPORTS=${CVE_ALLOW_RISKY_BACKPORTS}"
	einfo "CVE_DELAY=${CVE_DELAY}"
	einfo "CVE_LANG=${CVE_LANG}"

	if [[ "${G_UNATTENDED}" == "0" ]] ; then
		einfo "Accept the above environmental variables? (y/n)"
		read X
		if [[ "${X,,}" != "y" ]] ; then
			einfo "Rejected environmental variables.  Exiting."
			exit 0
		fi
	fi
}

validate_envars_and_globals() {
	[[ "${CVE_ALLOW_RISKY_BACKPORTS}" == 1 \
		|| "${CVE_ALLOW_RISKY_BACKPORTS}" == 0 ]] \
		|| CVE_FIX_REJECT_DISPUTED=0
	[[ "${CVE_DELAY}" == 1 || "${CVE_DELAY}" == 0 ]] \
		|| CVE_DELAY=0
	[[ "${CVE_FIX_REJECT_DISPUTED}" == 1 \
		|| "${CVE_FIX_REJECT_DISPUTED}" == 0 ]] \
		|| CVE_FIX_REJECT_DISPUTED=0
	[[ "${CVE_LANG}" == "en" ]] || CVE_LANG="en"
	if [[ ! -d "${G_CACHE_FOLDER}" ]] ; then
		eerror \
"G_CACHE_FOLDER does not point to a directory.  Exiting..."
		exit 1
	fi
	if [[ "${G_CACHE_FOLDER}" == "/" ]] ; then
		eerror \
"G_CACHE_FOLDER points to a root.  Dangerous.  Exiting..."
		exit 1
	fi
	if [[ ! -d "${G_KERNEL_SOURCE_FOLDER}" ]] ; then
		eerror \
"G_KERNEL_SOURCE_FOLDER does not point to a directory.  Exiting..."
		exit 1
	fi
	if (( "${G_MIN_YEAR}" < ${G_MIN_YEAR_LIMIT} )) ; then
		eerror "G_MIN_YEAR must be >= ${G_MIN_YEAR_LIMIT}"
		exit 1
	fi
	if (( "${G_MAX_YEAR}" > ${G_MAX_YEAR_LIMIT} )) ; then
		eerror "G_MAX_YEAR must be <= ${G_MAX_YEAR_LIMIT}"
		exit 1
	fi
	if (( "${G_MAX_YEAR}" < "${G_MIN_YEAR}" )) ; then
		eerror \
"G_MAX_YEAR must be >= G_MIN_YEAR and between ${G_MIN_YEAR_LIMIT}-\
${G_MAX_YEAR_LIMIT}"
		exit 1
	fi
	if (( "${G_MIN_YEAR}" > "${G_MAX_YEAR}" )) ; then
		eerror \
"G_MIN_YEAR must be >= G_MAX_YEAR and between ${G_MIN_YEAR_LIMIT}-\
${G_MAX_YEAR_LIMIT}"
		exit 1
	fi
	if [[ "${G_DOWNLOAD_TOOL}" == "curl" \
		|| "${G_DOWNLOAD_TOOL}" == "wget" ]] ; then
		:;
	else
		eerror "G_DOWNLOAD_TOOL must be curl or wget"
		exit 1
	fi
	if [[ -n "${CVE_BLACKLIST_FIXES}" ]] ; then
		for c in ${CVE_BLACKLIST_FIXES} ; do
			if echo "${c}" \
			 | grep -P -e "^CVE-[0-9]{4}-[0-9]+$"
			then
				:;
			else
				eerror \
"${c} is invalid for a CVE ID.  It must be all caps and in CVE-YYYY-XXXX format"
				exit 1
			fi
		done
	fi
	if [[ ! -d "${G_TEMP_DIR}" ]] ; then
		eerror "The temp directory is not set or doesn't exist.  See --help."
		exit 1
	fi
}

main() {
	einfo "Project is still WIP"

	arg_parse
	review_envars
	setup_globals
	validate_envars_and_globals

	local X_VERSION
	local X_PATCH_META_VERSION
	local X_TUXPARONI_URL_RESOLVER_HASH
	local need_wipe=0

	if [[ -f "${G_CACHE_FOLDER}/status" ]] ; then
		X_VERSION=$(\
			grep -e "tuxparoni_version:" "${G_CACHE_FOLDER}/status" \
			| cut -f2 -d $' ')
		X_PATCH_META_VERSION=$(\
			grep -e "meta_version:" "${G_CACHE_FOLDER}/status" \
			| cut -f2 -d $' ')
		X_TUXPARONI_URL_RESOLVER_HASH=$(\
			grep -e "resolver_hash:" "${G_CACHE_FOLDER}/status" \
			| cut -f2 -d $' ')

		[[ "${X_VERSION}" != "${G_VERSION}" ]] \
			&& need_wipe=1
		[[ "${X_PATCH_META_VERSION}" != "${G_PATCH_META_VERSION}" ]] \
			&& need_wipe=1
		[[ "${X_TUXPARONI_URL_RESOLVER_HASH}" != "${G_TUXPARONI_URL_RESOLVER_HASH}" ]] \
			&& need_wipe=1
	else
		need_wipe=1
	fi

	if [[ "${G_REQ_CLEAR_CACHE}" == "1" || "${need_wipe}" == "1" ]] ; then
		clear_cache
	fi

	# this is used to wipe the cache if necessary
	echo "tuxparoni_version: ${G_VERSION}" > "${G_CACHE_FOLDER}/status"
	echo "meta_version: ${G_PATCH_META_VERSION}" >> "${G_CACHE_FOLDER}/status"
	echo "resolver_hash: ${G_TUXPARONI_URL_RESOLVER_HASH}" >> "${G_CACHE_FOLDER}/status"

	G_KERNEL_TAG=$(get_tag)
	local ver=$(echo ${G_KERNEL_TAG} | cut -f1 -d "-")
	einfo "Kernel tag: ${G_KERNEL_TAG}"

	G_KERNEL_TIMESTAMP=$(get_kernel_timestamp "${ver}")
	einfo "Kernel release timestamp: ${G_KERNEL_TIMESTAMP}   "\
$(date -d "@${G_KERNEL_TIMESTAMP}")

	if [[ "${G_TUXPARONI_URL_RESOLVER_HASH}" \
		!= $(sha256sum "${DIR}/tuxparoni-url-resolver" \
			| cut -f1 -d " ") ]]
	then
		eerror "Resolver module is not authorized."
		exit 1
	fi

	setup_cache
	[[ "${G_REQ_FETCH_JSONS}" == "1" ]] && fetch_feeds
	[[ "${G_REQ_FETCH_JSONS}" == "1" ]] && unpack_feeds
	[[ "${G_REQ_FETCH_JSONS}" == "1" ]] && filter_jsons
	[[ "${G_REQ_FETCH_PATCHES}" == "1" ]] && fetch_patches
	[[ "${G_REQ_FETCH_PATCHES}" == "1" ]] && dedupe_patches_by_hash
	[[ "${G_REQ_FETCH_PATCHES}" == "1" ]] && tidy_patches

	[[ "${G_REQ_KPATCH_MODULES}" == "1" ]] && kpatch_combine

	[[ "${G_REQ_REPORT}" == "1" ]] && report_cves_patches_only
	[[ "${G_REQ_REPORT}" == "1" ]] && report_cves_json_only
	[[ "${G_REQ_DRY_TEST}" == "1" ]] && drytest_cves
	[[ "${G_REQ_BUILD_KPATCHES}" == "1" ]] && generate_kpatch_modules
	[[ "${G_REQ_APPLY_PATCHES}" == "1" ]] && apply_patches

	exit 0
}

main
